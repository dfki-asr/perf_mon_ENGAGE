{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc74c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Input, Flatten,\\\n",
    "Conv2DTranspose, BatchNormalization, LeakyReLU, Reshape, MaxPooling2D, concatenate, InputLayer, Lambda\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1855d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "# Load CIFAR-10 dataset-\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a0baa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "456437ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify hyper-parameters-\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensions of training and testing sets are:\n",
      "X_train.shape: (50000, 32, 32, 3) & X_test.shape: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Convert datasets to floating point types-\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalize the training and testing datasets-\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "\n",
    "\n",
    "# X_train, X_test = X_train.reshape(X_train.shape[0], -1), X_test.reshape(X_test.shape[0], -1)\n",
    "# Create TF datasets-\n",
    "\n",
    "\n",
    "print(\"\\nDimensions of training and testing sets are:\")\n",
    "print(f\"X_train.shape: {X_train.shape} & X_test.shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape: (50000, 10) & y_test.shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "print(f\"y_train.shape: {y_train.shape} & y_test.shape: {y_test.shape}\")\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train) ).shuffle(50000).batch(batch_size = batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(10000).batch(batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21b41e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(Model):\n",
    "    def __init__(\n",
    "        self, num_filters,\n",
    "        kernel_size, stride_length,\n",
    "        pooling_size, pooling_stride,\n",
    "        padding_type = 'same'\n",
    "    ):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2D(\n",
    "            filters = num_filters, kernel_size = kernel_size,\n",
    "            strides = stride_length, padding = padding_type,\n",
    "            activation = None, use_bias = False,\n",
    "        )\n",
    "        self.bn = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "        \n",
    "        self.conv2 = Conv2D(\n",
    "            filters = num_filters, kernel_size = kernel_size,\n",
    "            strides = stride_length, padding = padding_type,\n",
    "            activation = None, use_bias = False\n",
    "        )\n",
    "        self.bn2 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "        \n",
    "        self.pool = MaxPooling2D(\n",
    "            pool_size = pooling_size,\n",
    "            strides = pooling_stride\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def call(self, x):\n",
    "        x = tf.keras.activations.relu(self.bn(self.conv1(x)))\n",
    "        x = tf.keras.activations.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be5ad095",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv6_Encoder(Model):\n",
    "    def __init__(self, latent_dim = 10):\n",
    "        super(Conv6_Encoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.conv_block1 = ConvBlock(\n",
    "            num_filters = 64, kernel_size = 3,\n",
    "            stride_length = 1, pooling_size = 2,\n",
    "            pooling_stride = 2, padding_type = 'valid'\n",
    "            )\n",
    "\n",
    "        self.conv_block2 = ConvBlock(\n",
    "            num_filters = 128, kernel_size = 3,\n",
    "            stride_length = 1, pooling_size = 2,\n",
    "            pooling_stride = 2, padding_type = 'valid'\n",
    "            )\n",
    "        \n",
    "        self.conv_block3 = ConvBlock(\n",
    "            num_filters = 256, kernel_size = 3,\n",
    "            stride_length = 1, pooling_size = 2,\n",
    "            pooling_stride = 2, padding_type = 'same'\n",
    "            )\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "        self.output_layer = Dense(\n",
    "            units = self.latent_dim, activation = None\n",
    "            )\n",
    "        self.bn = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "        \n",
    "    \n",
    "    def call(self, x):\n",
    "        x1 = x[0]\n",
    "        x2 = x[1]\n",
    "        o = self.conv_block1(x1)\n",
    "        o = self.conv_block2(o)\n",
    "        o = self.conv_block3(o)\n",
    "#         res_shape = x.shape\n",
    "        o = self.flatten(o)\n",
    "        \n",
    "        o = K.concatenate([o,x2], axis=-1)\n",
    "        o = tf.keras.activations.relu(self.bn(self.output_layer(o)))\n",
    "        return o, x2\n",
    "    \n",
    "    def model(self):\n",
    "        '''\n",
    "        Overrides 'model()' call.\n",
    "        Output shape is not well-defined when using sub-classing. As a\n",
    "        workaround, this method is implemeted.\n",
    "        '''\n",
    "        x1 = Input(shape = (32,32,3))\n",
    "        x2 = Input(shape = (10,))\n",
    "        return Model(inputs = [x1,x2], outputs = self.call([x1,x2]))\n",
    "    \n",
    "    def shape_computation(self, x):\n",
    "        print(f\"Input shape: {x.shape}\")\n",
    "        x = self.conv_block1(x)\n",
    "        print(f\"conv_block1.shape: {x.shape}\")\n",
    "        x = self.conv_block2(x)\n",
    "        print(f\"conv_block2.shape: {x.shape}\")\n",
    "        x = self.conv_block3(x)\n",
    "        print(f\"conv_block3.shape: {x.shape}\")\n",
    "        x = self.flatten(x)\n",
    "        print(f\"flattened shape: {x.shape}\")\n",
    "        x = tf.keras.activations.relu(self.bn(self.output_layer(x)))\n",
    "        print(f\"Encoder output shape: {x.shape}\")\n",
    "        '''\n",
    "        Input shape: (64, 32, 32, 3)\n",
    "        conv_block1.shape: (64, 14, 14, 64)\n",
    "        conv_block2.shape: (64, 5, 5, 128)\n",
    "        conv_block3.shape: (64, 2, 2, 256)\n",
    "        flattened shape: (64, 1024)\n",
    "        Encoder output shape: (64, 100)\n",
    "        '''\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "741a36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv6_Decoder(Model):\n",
    "    def __init__(self, latent_dim = 10):\n",
    "        super(Conv6_Decoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "#         self.inp_layer = InputLayer(input_shape = self.latent_dim+10)\n",
    "        \n",
    "        print('In decoder')\n",
    "        self.dense0 = Dense(\n",
    "            units = self.latent_dim+10, activation = None\n",
    "            )\n",
    "        self.bn0 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "        \n",
    "        self.dense = Dense(\n",
    "            units = 1024, activation = None\n",
    "        )\n",
    "        self.bn = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "        \n",
    "        self.dense2 = Dense(\n",
    "            units = 4 * 4 * 256, activation = None\n",
    "        )\n",
    "        self.bn2 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "        \n",
    "        self.reshape = Reshape((4, 4, 256))\n",
    "        \n",
    "        self.conv_transpose_layer1 = Conv2DTranspose(\n",
    "            filters = 256, kernel_size = 3,\n",
    "            strides = 2, padding = 'same',\n",
    "            activation = None\n",
    "            )\n",
    "        self.bn3 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "       \n",
    "        self.conv_transpose_layer2 = Conv2DTranspose(\n",
    "            filters = 256, kernel_size = 3,\n",
    "            strides = 1, padding = 'same',\n",
    "            activation = None\n",
    "            )\n",
    "        \n",
    "        self.bn4 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "        \n",
    "        self.conv_transpose_layer3 =  Conv2DTranspose(\n",
    "            filters = 128, kernel_size = 3,\n",
    "            strides = 2, padding = 'same',\n",
    "            activation = None\n",
    "            )\n",
    "        self.bn5 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "        \n",
    "        self.conv_transpose_layer4 = Conv2DTranspose(\n",
    "            filters = 128, kernel_size = 3,\n",
    "            strides = 1, padding = 'same',\n",
    "            activation = None\n",
    "            )\n",
    "        \n",
    "        self.bn6 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "\n",
    "        self.conv_transpose_layer5 = Conv2DTranspose(\n",
    "            filters = 64, kernel_size = 3,\n",
    "            strides = 2, padding = 'same',\n",
    "            activation = None\n",
    "            )\n",
    "        self.bn7 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "       \n",
    "        self.conv_transpose_layer6 = Conv2DTranspose(\n",
    "            filters = 64, kernel_size = 3,\n",
    "            strides = 1, padding = 'same',\n",
    "            activation = None\n",
    "            )\n",
    "        \n",
    "        self.bn8 = BatchNormalization(\n",
    "            axis = -1, momentum = 0.99,\n",
    "            epsilon = 0.001\n",
    "            )\n",
    "        \n",
    "        self.final_conv_layer = Conv2DTranspose(\n",
    "            filters = 3, kernel_size = 3,\n",
    "            strides = 1, padding = 'same',\n",
    "            activation = None\n",
    "            )\n",
    "        \n",
    "    \n",
    "    def call(self, X):\n",
    "#         X = self.inp_layer(X)\n",
    "        x1 = X[0]\n",
    "        x2 = X[1]\n",
    "        X = K.concatenate([x1,x2])\n",
    "        X = tf.keras.activations.relu(self.bn0(self.dense0(X)))\n",
    "        X = tf.keras.activations.relu(self.bn(self.dense(X)))\n",
    "        X = tf.keras.activations.relu(self.bn2(self.dense2(X)))\n",
    "        X = self.reshape(X)\n",
    "        X = tf.keras.activations.relu(self.bn3(self.conv_transpose_layer1(X)))\n",
    "        X = tf.keras.activations.relu(self.bn4(self.conv_transpose_layer2(X)))\n",
    "        X = tf.keras.activations.relu(self.bn5(self.conv_transpose_layer3(X)))\n",
    "        X = tf.keras.activations.relu(self.bn6(self.conv_transpose_layer4(X)))\n",
    "        X = tf.keras.activations.relu(self.bn7(self.conv_transpose_layer5(X)))\n",
    "        X = tf.keras.activations.relu(self.bn8(self.conv_transpose_layer6(X)))\n",
    "        # X = tf.keras.activations.sigmoid(self.final_conv_layer(X))\n",
    "        X = self.final_conv_layer(X)\n",
    "\n",
    "        return X\n",
    "        \n",
    "    def model(self):\n",
    "        '''\n",
    "        Overrides 'model()' call.\n",
    "        Output shape is not well-defined when using sub-classing. As a\n",
    "        workaround, this method is implemeted.\n",
    "        '''\n",
    "        x1 = Input(shape = (100))\n",
    "        x2 = Input(shape=(10,))\n",
    "        return Model(inputs = [x1,x2], outputs = self.call([x1,x2]))\n",
    "    \n",
    "    def shape_computation(self, x):\n",
    "        print(f\"Input shape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn0(self.dense0(x)))\n",
    "        print(f\"first dense layer shape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn(self.dense(x)))\n",
    "        print(f\"second dense layer shape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn2(self.dense2(x)))\n",
    "        print(f\"third dense layer shape: {x.shape}\")\n",
    "        x = self.reshape(x)\n",
    "        print(f\"reshape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn3(self.conv_transpose_layer1(x)))\n",
    "        print(f\"conv transpose layer1 shape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn4(self.conv_transpose_layer2(x)))\n",
    "        print(f\"conv transpose layer2 shape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn5(self.conv_transpose_layer3(x)))\n",
    "        print(f\"conv transpose layer3 shape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn6(self.conv_transpose_layer4(x)))\n",
    "        print(f\"conv transpose layer4 shape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn7(self.conv_transpose_layer5(x)))\n",
    "        print(f\"conv transpose layer5 shape: {x.shape}\")\n",
    "        x = tf.nn.relu(self.bn8(self.conv_transpose_layer6(x)))\n",
    "        print(f\"conv transpose layer6 shape: {x.shape}\")\n",
    "        x = self.final_conv_layer(x)\n",
    "        print(f\"Decoder output shape: {x.shape}\")\n",
    "        \n",
    "        '''\n",
    "        Input shape: (64, 100)\n",
    "        first dense layer shape: (64, 100)\n",
    "        second dense layer shape: (64, 1024)\n",
    "        third dense layer shape: (64, 4096)\n",
    "        reshape: (64, 4, 4, 256)\n",
    "        conv transpose layer1 shape: (64, 8, 8, 256)\n",
    "        conv transpose layer2 shape: (64, 8, 8, 256)\n",
    "        conv transpose layer3 shape: (64, 16, 16, 128)\n",
    "        conv transpose layer4 shape: (64, 16, 16, 128)\n",
    "        conv transpose layer5 shape: (64, 32, 32, 64)\n",
    "        conv transpose layer6 shape: (64, 32, 32, 64)\n",
    "        Decoder output shape: (64, 32, 32, 3)\n",
    "        '''\n",
    "        \n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Create a sampling layer.\n",
    "    Uses (mu, log_var) to sample latent vector 'z'.\n",
    "    \"\"\"\n",
    "    def call(self, mu, log_var):\n",
    "    # def call(self, inputs):\n",
    "        # z_mean, z_log_var = inputs\n",
    "\n",
    "        # Get batch size-\n",
    "        batch = tf.shape(mu)[0]\n",
    "\n",
    "        # Get latent space dimensionality-\n",
    "        dim = tf.shape(mu)[1]\n",
    "\n",
    "        # Add stochasticity by sampling from a multivariate standard \n",
    "        # Gaussian distribution-\n",
    "        epsilon = tf.keras.backend.random_normal(\n",
    "            shape = (batch, dim), mean = 0.0,\n",
    "            stddev = 1.0\n",
    "        )\n",
    "        z = mu + (tf.exp(0.5 * log_var) * epsilon)\n",
    "        return z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    def __init__(self, latent_space = 100):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.latent_space = latent_space\n",
    "        self.encoder = Conv6_Encoder(latent_dim = self.latent_space)\n",
    "        self.decoder = Conv6_Decoder(latent_dim = self.latent_space)\n",
    "        \n",
    "        # Define fully-connected layers for computing mean & log variance-\n",
    "        self.mu = Dense(units = self.latent_space, activation = None)\n",
    "        self.log_var = Dense(units = self.latent_space, activation = None)\n",
    "\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # Sample from a multivariate Gaussian distribution.\n",
    "        # Adds stochasticity or variation-\n",
    "        eps = tf.random.normal(\n",
    "            shape = mu.shape, mean = 0.0,\n",
    "            stddev = 1.0\n",
    "        )\n",
    "        return (eps * tf.exp(logvar * 0.5) + mu)\n",
    "        \n",
    "    \n",
    "    def call(self, x):\n",
    "        latent, label = self.encoder(x)\n",
    "        # x.shape: (batch_size, 100)\n",
    "        mu = self.mu(latent)\n",
    "        log_var = self.log_var(latent)\n",
    "        # z = self.reparameterize(mu, log_var)\n",
    "        # z = Sampling()([mu, log_var])\n",
    "        z = Sampling()(mu, log_var)\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        print(f\"mu.shape: {mu.shape}, log_var.shape: {log_var.shape}\"\n",
    "              f\" & z.shape: {z.shape}\")\n",
    "        # mu.shape: (batch_size, 100), log_var.shape: (batch_size, 100) & z.shape: (batch_size, 100)\n",
    "        '''\n",
    "        x = tf.keras.activations.sigmoid(self.decoder([z, label]))\n",
    "        return x, mu, log_var, z\n",
    "    \n",
    "    \n",
    "    def model(self):\n",
    "        '''\n",
    "        Overrides 'model()' call.\n",
    "        Output shape is not well-defined when using sub-classing. As a\n",
    "        workaround, this method is implemeted.\n",
    "        '''\n",
    "        x1 = Input(shape = (32,32,3))\n",
    "        x2 = Input(shape = (10,))\n",
    "        return Model(inputs = [x1,x2], outputs = self.call([x1,x2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In decoder\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " conv6__encoder (Conv6_Encoder)  ((None, 100),       1251996     ['input_1[0][0]',                \n",
      "                                 (None, 10))                      'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 100)          10100       ['conv6__encoder[0][0]']         \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 100)          10100       ['conv6__encoder[0][0]']         \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 100)          0           ['dense_4[0][0]',                \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv6__decoder (Conv6_Decoder)  (None, 32, 32, 3)   6084013     ['sampling[0][0]',               \n",
      "                                                                  'conv6__encoder[0][1]']         \n",
      "                                                                                                  \n",
      " tf.math.sigmoid (TFOpLambda)   (None, 32, 32, 3)    0           ['conv6__decoder[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,356,209\n",
      "Trainable params: 7,341,965\n",
      "Non-trainable params: 14,244\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize VAE model-\n",
    "model = VAE(latent_space = 100)\n",
    "model.model().summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, mu, log_var, z = model.predict([X_train[0].reshape(1,32,32,3),y_train[0].reshape(1,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get model summary-\n",
    "# model.decoder.model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an optimizer-\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(data, reconstruction, mu, log_var, alpha = 1):\n",
    "    \n",
    "    # Reconstruction loss-\n",
    "    # recon_loss = tf.keras.losses.mean_squared_error(K.flatten(data), K.flatten(reconstruction))\n",
    "\n",
    "    recon_loss = tf.reduce_mean(\n",
    "        tf.reduce_sum(\n",
    "            tf.keras.losses.binary_crossentropy(data[0], reconstruction), axis=(1, 2)\n",
    "#             tf.keras.losses.mean_squared_error(data, reconstruction),\n",
    "#             axis = (1, 2)\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # KL-divergence loss-    \n",
    "    kl_loss = -0.5 * (1 + log_var - tf.square(mu) - tf.exp(log_var))\n",
    "    kl_loss = tf.reduce_mean(\n",
    "        tf.reduce_sum(\n",
    "            kl_loss,\n",
    "            axis = 1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    total_loss = (recon_loss * alpha) + kl_loss\n",
    "    \n",
    "    return total_loss, recon_loss, kl_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_one_step(model, optimizer, data, alpha):\n",
    "    # Function to perform one step/iteration of training\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Make predictions using defined model-\n",
    "        data_recon, mu, log_var, z = model(data)\n",
    "\n",
    "        # Compute loss-\n",
    "        total_loss, recon_loss, kl_loss = compute_loss(\n",
    "            data = data, reconstruction = data_recon,\n",
    "            mu = mu, log_var = log_var,\n",
    "            alpha = alpha\n",
    "        )\n",
    "    \n",
    "    # Compute gradients wrt defined loss and weights and biases-\n",
    "    grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "    \n",
    "    # type(grads)\n",
    "    # list\n",
    "    \n",
    "    # Apply computed gradients to model's weights and biases-\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    return total_loss, recon_loss, kl_loss\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(model, optimizer, data, alpha):\n",
    "    '''\n",
    "    Function to test model performance\n",
    "    on testing dataset\n",
    "    '''\n",
    "    # Make predictions using defined model-\n",
    "    data_recon, mu, log_var, z = model(data)\n",
    "    \n",
    "    # Compute loss-\n",
    "    total_loss, recon_loss, kl_loss = compute_loss(\n",
    "        data = data, reconstruction = data_recon,\n",
    "        mu = mu, log_var = log_var,\n",
    "        alpha = alpha\n",
    "    )\n",
    "    \n",
    "    return total_loss, recon_loss, kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify hyper-parameter for reconstruction loss vs. kl-divergence-\n",
    "alpha = 10\n",
    "\n",
    "# Python3 dict to contain training metrics-\n",
    "training_metrics = {}\n",
    "val_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1; total train loss = 5176863.0156, train recon loss = 515480.1829, train kl loss = 22061.1704; total val loss = 1004521.7871, val recon loss = 99678.4008 & val kl loss = 7737.7751\n",
      "epoch = 2; total train loss = 4949607.1875, train recon loss = 490673.0542, train kl loss = 42876.6502; total val loss = 989911.0967, val recon loss = 98101.7460 & val kl loss = 8893.6342\n",
      "epoch = 3; total train loss = 4904179.9312, train recon loss = 485777.5630, train kl loss = 46404.2979; total val loss = 982145.0356, val recon loss = 97230.7553 & val kl loss = 9837.4823\n",
      "epoch = 4; total train loss = 4857229.5103, train recon loss = 480558.8591, train kl loss = 51640.9305; total val loss = 972488.5581, val recon loss = 96174.1843 & val kl loss = 10746.7150\n",
      "epoch = 5; total train loss = 4826191.3960, train recon loss = 477264.4634, train kl loss = 53546.7571; total val loss = 968110.1533, val recon loss = 95714.8879 & val kl loss = 10961.2729\n",
      "epoch = 6; total train loss = 4809860.0762, train recon loss = 475597.7585, train kl loss = 53882.4841; total val loss = 967516.1353, val recon loss = 95648.7191 & val kl loss = 11028.9420\n",
      "epoch = 7; total train loss = 4795080.5308, train recon loss = 473993.0120, train kl loss = 55150.4071; total val loss = 964613.3794, val recon loss = 95332.6099 & val kl loss = 11287.2823\n",
      "epoch = 8; total train loss = 4781451.0986, train recon loss = 472507.4532, train kl loss = 56376.5702; total val loss = 960905.5161, val recon loss = 94957.9354 & val kl loss = 11326.1602\n",
      "epoch = 9; total train loss = 4770582.5034, train recon loss = 471417.2000, train kl loss = 56410.5031; total val loss = 959567.6035, val recon loss = 94835.0740 & val kl loss = 11216.8637\n",
      "epoch = 10; total train loss = 4762210.5581, train recon loss = 470624.4337, train kl loss = 55966.2257; total val loss = 959058.4380, val recon loss = 94776.7516 & val kl loss = 11290.9250\n",
      "epoch = 11; total train loss = 4753773.2065, train recon loss = 469828.0993, train kl loss = 55492.2229; total val loss = 955800.2861, val recon loss = 94481.5355 & val kl loss = 10984.9334\n",
      "epoch = 12; total train loss = 4746760.4136, train recon loss = 469164.3571, train kl loss = 55116.8376; total val loss = 954510.9297, val recon loss = 94344.6455 & val kl loss = 11064.4736\n",
      "epoch = 13; total train loss = 4739292.4980, train recon loss = 468441.7738, train kl loss = 54874.7519; total val loss = 952706.5146, val recon loss = 94177.1003 & val kl loss = 10935.5159\n",
      "epoch = 14; total train loss = 4733963.8330, train recon loss = 467958.9429, train kl loss = 54374.4036; total val loss = 952056.2871, val recon loss = 94108.4860 & val kl loss = 10971.4239\n",
      "epoch = 15; total train loss = 4727531.9985, train recon loss = 467356.3336, train kl loss = 53968.6622; total val loss = 950776.4590, val recon loss = 93996.5992 & val kl loss = 10810.4627\n",
      "epoch = 16; total train loss = 4721650.8540, train recon loss = 466788.5989, train kl loss = 53764.8640; total val loss = 950986.0127, val recon loss = 94067.2860 & val kl loss = 10313.1481\n",
      "epoch = 17; total train loss = 4715903.7852, train recon loss = 466213.5543, train kl loss = 53768.2425; total val loss = 948665.4077, val recon loss = 93783.0950 & val kl loss = 10834.4587\n",
      "epoch = 18; total train loss = 4710462.6621, train recon loss = 465649.1741, train kl loss = 53970.9237; total val loss = 948307.1924, val recon loss = 93760.9329 & val kl loss = 10697.8613\n",
      "epoch = 19; total train loss = 4704865.5645, train recon loss = 465066.4299, train kl loss = 54201.2750; total val loss = 947255.2222, val recon loss = 93636.7296 & val kl loss = 10887.9291\n",
      "epoch = 20; total train loss = 4700167.1660, train recon loss = 464594.0537, train kl loss = 54226.6191; total val loss = 945266.8066, val recon loss = 93440.0481 & val kl loss = 10866.3259\n",
      "epoch = 21; total train loss = 4695923.9478, train recon loss = 464169.5374, train kl loss = 54228.5787; total val loss = 944586.3608, val recon loss = 93380.2658 & val kl loss = 10783.7065\n",
      "epoch = 22; total train loss = 4692685.6377, train recon loss = 463862.4063, train kl loss = 54061.5711; total val loss = 944059.6318, val recon loss = 93320.1132 & val kl loss = 10858.5005\n",
      "epoch = 23; total train loss = 4688224.0044, train recon loss = 463411.8294, train kl loss = 54105.7190; total val loss = 944597.8408, val recon loss = 93381.7081 & val kl loss = 10780.7580\n",
      "epoch = 24; total train loss = 4685191.2915, train recon loss = 463104.0176, train kl loss = 54151.1207; total val loss = 943137.7515, val recon loss = 93216.8709 & val kl loss = 10969.0444\n",
      "epoch = 25; total train loss = 4681698.6230, train recon loss = 462764.2027, train kl loss = 54056.5946; total val loss = 942615.4048, val recon loss = 93183.6301 & val kl loss = 10779.1079\n",
      "epoch = 26; total train loss = 4679579.7036, train recon loss = 462550.4033, train kl loss = 54075.6760; total val loss = 942047.9844, val recon loss = 93121.9268 & val kl loss = 10828.7154\n",
      "epoch = 27; total train loss = 4676772.6455, train recon loss = 462277.0782, train kl loss = 54001.8620; total val loss = 941409.0811, val recon loss = 93054.2551 & val kl loss = 10866.5270\n",
      "epoch = 28; total train loss = 4674512.8892, train recon loss = 462061.4043, train kl loss = 53898.8442; total val loss = 941049.9678, val recon loss = 93033.7947 & val kl loss = 10712.0243\n",
      "epoch = 29; total train loss = 4672108.8164, train recon loss = 461823.5419, train kl loss = 53873.3935; total val loss = 941464.9409, val recon loss = 93048.8839 & val kl loss = 10976.1044\n",
      "epoch = 30; total train loss = 4669963.3325, train recon loss = 461608.3842, train kl loss = 53879.4843; total val loss = 940429.6738, val recon loss = 92959.0296 & val kl loss = 10839.3737\n",
      "epoch = 31; total train loss = 4667768.1758, train recon loss = 461391.8980, train kl loss = 53849.1895; total val loss = 942256.8721, val recon loss = 93153.1009 & val kl loss = 10725.8657\n",
      "epoch = 32; total train loss = 4665617.2852, train recon loss = 461175.3030, train kl loss = 53864.2538; total val loss = 939358.7065, val recon loss = 92853.8575 & val kl loss = 10820.1289\n",
      "epoch = 33; total train loss = 4663995.2798, train recon loss = 461010.0535, train kl loss = 53894.7449; total val loss = 939643.4658, val recon loss = 92870.2297 & val kl loss = 10941.1703\n",
      "epoch = 34; total train loss = 4661677.4873, train recon loss = 460766.8353, train kl loss = 54009.1326; total val loss = 939151.5156, val recon loss = 92836.6803 & val kl loss = 10784.7132\n",
      "epoch = 35; total train loss = 4660225.2021, train recon loss = 460621.9932, train kl loss = 54005.2692; total val loss = 939390.6343, val recon loss = 92872.5109 & val kl loss = 10665.5281\n",
      "epoch = 36; total train loss = 4658154.7944, train recon loss = 460404.6442, train kl loss = 54108.3547; total val loss = 939263.5796, val recon loss = 92842.4797 & val kl loss = 10838.7838\n",
      "epoch = 37; total train loss = 4656758.9478, train recon loss = 460260.5298, train kl loss = 54153.6549; total val loss = 938882.1265, val recon loss = 92782.9628 & val kl loss = 11052.4997\n",
      "epoch = 38; total train loss = 4655063.9888, train recon loss = 460094.9082, train kl loss = 54114.9020; total val loss = 939034.6558, val recon loss = 92811.7944 & val kl loss = 10916.7088\n",
      "epoch = 39; total train loss = 4653575.6538, train recon loss = 459945.1249, train kl loss = 54124.4122; total val loss = 939129.2959, val recon loss = 92820.7950 & val kl loss = 10921.3480\n",
      "epoch = 40; total train loss = 4651801.8745, train recon loss = 459762.0435, train kl loss = 54181.4491; total val loss = 938453.9429, val recon loss = 92767.5496 & val kl loss = 10778.4451\n",
      "epoch = 41; total train loss = 4650946.6377, train recon loss = 459683.4340, train kl loss = 54112.2975; total val loss = 938335.3047, val recon loss = 92757.2773 & val kl loss = 10762.5338\n",
      "epoch = 42; total train loss = 4649299.3188, train recon loss = 459514.3785, train kl loss = 54155.5347; total val loss = 938105.0317, val recon loss = 92739.7417 & val kl loss = 10707.6119\n",
      "epoch = 43; total train loss = 4647684.9980, train recon loss = 459354.6370, train kl loss = 54138.6237; total val loss = 938241.8896, val recon loss = 92744.4277 & val kl loss = 10797.6163\n",
      "epoch = 44; total train loss = 4646979.9536, train recon loss = 459286.3298, train kl loss = 54116.6584; total val loss = 937941.6357, val recon loss = 92721.7870 & val kl loss = 10723.7629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 45; total train loss = 4645184.7998, train recon loss = 459102.5937, train kl loss = 54158.8648; total val loss = 938240.5088, val recon loss = 92751.3732 & val kl loss = 10726.7772\n",
      "epoch = 46; total train loss = 4643781.9263, train recon loss = 458957.0797, train kl loss = 54211.1237; total val loss = 937718.6113, val recon loss = 92686.6010 & val kl loss = 10852.6019\n",
      "epoch = 47; total train loss = 4642486.1650, train recon loss = 458824.7676, train kl loss = 54238.4929; total val loss = 938103.8286, val recon loss = 92727.5109 & val kl loss = 10828.7202\n",
      "epoch = 48; total train loss = 4641008.7627, train recon loss = 458684.1209, train kl loss = 54167.5565; total val loss = 937984.2061, val recon loss = 92719.2225 & val kl loss = 10791.9803\n",
      "epoch = 49; total train loss = 4640140.1768, train recon loss = 458590.5870, train kl loss = 54234.3000; total val loss = 938491.6660, val recon loss = 92767.9165 & val kl loss = 10812.5021\n",
      "epoch = 50; total train loss = 4638279.3149, train recon loss = 458397.4382, train kl loss = 54304.9476; total val loss = 937981.0190, val recon loss = 92704.6444 & val kl loss = 10934.5734\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    \"\"\"\n",
    "    # Manual early stopping implementation-\n",
    "    if loc_patience >= patience:\n",
    "        print(\"\\n'EarlyStopping' called!\\n\")\n",
    "        break\n",
    "    \"\"\"\n",
    "\n",
    "    # Epoch train & validation losses-\n",
    "    train_loss = 0.0\n",
    "    train_r_loss = 0.0\n",
    "    train_kl_l = 0.0\n",
    "    val_loss = 0.0\n",
    "    val_r_loss = 0.0\n",
    "    val_kl_l = 0.0\n",
    "    \n",
    "    for data in train_dataset:\n",
    "        train_total_loss, train_recon_loss, train_kl_loss = train_one_step(\n",
    "            model = model, optimizer = optimizer,\n",
    "            data = list(data), alpha = alpha\n",
    "        )\n",
    "        \n",
    "        train_loss += train_total_loss.numpy()\n",
    "        train_r_loss += train_recon_loss.numpy()\n",
    "        train_kl_l += train_kl_loss.numpy()\n",
    "    \n",
    "    for test_data in test_dataset:\n",
    "        test_total_loss, test_recon_loss, test_kl_loss = test_step(\n",
    "            model = model, optimizer = optimizer,\n",
    "            data = test_data, alpha = alpha)\n",
    "        \n",
    "        val_loss += test_total_loss.numpy()\n",
    "        val_r_loss += test_recon_loss.numpy()\n",
    "        val_kl_l += test_kl_loss.numpy()\n",
    "    \n",
    "    # vae_train_loss.append(train_loss)\n",
    "    # vae_val_loss.append(val_loss)\n",
    "\n",
    "    training_metrics[epoch] = {\n",
    "        'total_loss': train_loss, 'recon_loss': train_r_loss,\n",
    "        'kl_loss': train_kl_l\n",
    "        }\n",
    "    \n",
    "    val_metrics[epoch] = {\n",
    "        'total_loss': val_loss, 'recon_loss': val_r_loss,\n",
    "        'kl_loss': val_kl_l\n",
    "    }\n",
    "\n",
    "    print(f\"epoch = {epoch}; total train loss = {train_loss:.4f},\"\n",
    "    f\" train recon loss = {train_r_loss:.4f}, train kl loss = {train_kl_l:.4f};\"\n",
    "    f\" total val loss = {val_loss:.4f}, val recon loss = {val_r_loss:.4f} &\"\n",
    "    f\" val kl loss = {val_kl_l:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('vgg_based_250')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = X_test[:2000]\n",
    "y_data = y_test[:2000]\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe596cbcf40>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAe/0lEQVR4nO2dW4xc15We/1X36qq+sNlkiyIpkaIo60LdewgF40wsyx5ojAFkCzOyncDQgzEcBGMgBiYPggPEDpAHTxDb8JMDOhasCTy+xJJjZeKJLSvOCJMH2ZRGoi7UjTRFkeKlSTb7xu66nZWHKmIoYf+7W2R3taz9f0Cjq/fqfc6uXXudU7X/WmuZu0MI8cEnt9YDEEL0Bzm7EIkgZxciEeTsQiSCnF2IRJCzC5EIhcvpbGb3AvgmgDyA/+ruX439f7FY9HK5HLQ5VlYCNOfXsUKen6ta4lPSId0aLT6OXJ6PY/3oCLWdX1igtpnpGWrLsizYPlir0D61Sp7a8kZNsNhrlmPPmx/QLGLLRQYSu2eRY8YUZw9PIQCg3elQW6PZprZWpF+nEz5hu837ZOQJLDYaaLXawSdtl6qzm1kewGsAPg7gKIDfAPisu7/M+tTrdd+169agrYOIx5C1mEUWW7HNF/fGGu934/ZRaptZDL8ohyZpF9SHBqjtX336Pmrbv/9Favv5z5+gtrm588H2u++6gfb5vZ3D1DZc5iu/mOOLEaXwRd0K4XYAKBf4hTZPjgcAiBwTuWKwuZ3xC0Rznq+P01Nz1PbbY6eo7eTULLWdnQkfc2qKX9QXGs1g+779BzA7Nx909st5G78bwBvufsjdmwB+AICvXiHEmnI5zr4ZwFsX/X201yaEeB9yWZ/Zl4OZ7QGwBwBKpdJqn04IQbicO/sxAFsv+ntLr+0duPted59w94liMfz5SQix+lyOs/8GwE4z225mJQCfAfD4ygxLCLHSXPLbeHdvm9kXAPwc3f3yh939pVifzB2L7cWgzSKqANv0LURkrdHiPLXdvJ1vLWzdsp6Po7Yx2H7/7R+jfaZOn6W2gSKf/nv+xT+ntgK4xPPkk78MtpfzXO2IvuEyvuNuOb5Tb94ItmctPo7M+a66gZ8rl/Ex5gvhj46VyJMuDfL5vXKEqzw3bN9BbfNNPsa5hfCcHDrG184rrx0Ktr/0Kl9Tl/WZ3d1/BuBnl3MMIUR/0DfohEgEObsQiSBnFyIR5OxCJIKcXYhEWPVv0L0TR+ZhWSOm/uSJ6jJY4b12batT244ruXxSrvDr38CGcJDMTTftpH0OHjhIbZ3zPKhiICIN3fORD1PbyGBYajp99BXapxWRw1qRYCPPeL+KheexEgloKRT43OeMS2+FiATYaYejB3O5SOCVhWVDAIDz18VYxBaAWpn3qw2EbRvHttE+N+/cFGx/4v+9QPvozi5EIsjZhUgEObsQiSBnFyIR5OxCJEJfd+MNQNHCu7vFyM7uYDk8zBuu2kD77LiS7yJXIkEhLIcbAGzZvCXYPnn8KO3TaoYDfwBgZGiI2ipkhxYA8k3+3CYm7gy2nxjn6sTc5GFqa0bShRnNMwe0O+Ed7Xw7cjzjO/U5srsPALlI0rgCS6JHVCEAaBd53gWPjIPlKOwSCRoia78ErtYMlcPPK5eLBJRRixDiA4WcXYhEkLMLkQhydiESQc4uRCLI2YVIhP4Gwrgj3wnLDPUCz9G1c1M4AOW6K2u0TyV/jto6GX/aA3VeEWZwMGx7dv/ztE+xwCvCDGzZSm0l48E6kXRmmCdVa6p1nluvsRCuIgMAnRYPCml1eJ4/IyWNPJIvrhwJhPGIrpXL82OWLByckieVYgBgIRLskkXktZgUGVPlijkyxg6XB1kxrFhJLt3ZhUgEObsQiSBnFyIR5OxCJIKcXYhEkLMLkQiXJb2Z2WEAswA6ANruPhH7/xwAJihtu2Id7XfT9rFgez3Hi9XnC0ycAFrgUU3br72F2qanwzLUzNlp2qcyxKOdTs9MUdvU/Cy1ufPn1mmHr9/mXKasreMSYLHEl0hj5hS1Nc+EJdZCJPdby2P3nsjrmXEbPCzLlfORMkkRCc0iUW/5yBgRicyzVniMBi4p5ohcFxnBiujsd7v76RU4jhBiFdHbeCES4XKd3QH8wsyeMbM9KzEgIcTqcLlv4z/s7sfMbCOAJ8zsFXd/6uJ/6F0E9gBAOVKiWAixulzWnd3dj/V+nwLwEwC7A/+z190n3H2iWJCzC7FWXLKzm1nNzAYvPAbwhwBeXKmBCSFWlsu51Y4D+ImZXTjO37j7/451KBXy2EJKKO3cyqPNBvLN8PGMJ3NsOk9eWB3mEWDl2gi1vXrgSLC9Q6QTAChEyji9fYpLVy+//Cq1nT3LZblCPvy8b/rQNbTPtq3j1FaLRAGWClzCXGiHX5uF6ZO0TzlfpbZilZ8rI+cCAGcJGI2LVPl2eL0BgEXErazNo9Ro4ksATOnzXMQ9I/IgHcN77nFhIO6HANx6qf2FEP1F0psQiSBnFyIR5OxCJIKcXYhEkLMLkQh9/ZZLtZTDLZvD0VejOZ70kOWibCAc+QMA0w1+Hdtc5zXWXjvMJa8mSV546O23aZ+TL/LjnZjkUW/T53gkXRbJeshspydP0D6N3bdT2631YWob37CN2qwYri3XqnDprbHI52NsHZdLrcNronUWw5GRnUiSyrxz6a0TSfbZIesDADzHo95owkyPuCc5nEcyW+rOLkQiyNmFSAQ5uxCJIGcXIhHk7EIkQl9343MG1EvhYAGLlAVabIWDSRbakRI+hfBuMACcb0WCKjKeI60wED7mwSNv0T5HjvGMXc0m36GtVnlQiLHgDgA5C9uOvn2c9vm7v5uktsOH+XO752P3UNvNu8K5/Mau2Eb7HHn9ZWo7cZoH/2zbchW1jYyHX+v5aR6E1GlwW2MxEiRT4q+L53i/phMlKuPrw0l+uliZKd3ZhUgEObsQiSBnFyIR5OxCJIKcXYhEkLMLkQh9ld7MAFZ1JysM0H6NXNg2MLqF9tm44Wpqa0cCFg68dpDaTs8cCrZPTvEyVLHABIvkQfNIxywiyRRIBt8sUlppoREuawUAzz3/PLW9cZDP1f333x9s/+jdH6V9Nly5g9rePPgGtRWrm6htZCxcOqzV5DkKG20+v5Uql4hrNVbcDMgVeZ68o8deD7Yvnuevy8gQO1ck1x21CCE+UMjZhUgEObsQiSBnFyIR5OxCJIKcXYhEWFJ6M7OHAfwxgFPuvqvXNgrghwC2ATgM4AF35wnEejgcmYeli0bGI9hqG7YH20/wQChMHjtMbacmeSTakePHqK3BIvMipX08IoUUClwCjMlyMS6lX6HEZahOJOna5Fn+kv/4sZ8E2+sj62ifG2+8kdvu4HnyakU+/rdPh3P5TU/z6Maycxm4XOIu43m+hmfmF6itRUqVeZ6vj9JAODeg5Xif5dzZvwvg3ne1PQTgSXffCeDJ3t9CiPcxSzp7r9762Xc13wfgkd7jRwB8cmWHJYRYaS71M/u4u1/IhnAC3YquQoj3MZe9Qefd73XS73aa2R4z22dm++YW+OckIcTqcqnOftLMNgFA7zfN4+Pue919wt0n6lW+gSGEWF0u1dkfB/Bg7/GDAH66MsMRQqwWy5Hevg/gIwDGzOwogC8D+CqAH5nZ5wG8CeCB5Zys08kwNT0ftB14+wztN/dyWD45cY7LQjOzPGKoVg+XoAKASp0nekQrLJ/ErpgsCg0AOpHoqpiEViy+93dInUjJqFKkjFazyecx6/Bjzs2Fkyg++tiP+bnwR9R21+/tpraG84+HC+1wRGJ9dJD2aU3z57zYjjznKS6vnZjk67tSDUewbbxiI+2znkTzFYo8meqSzu7unyUmnlpUCPG+Q9+gEyIR5OxCJIKcXYhEkLMLkQhydiESoa8JJ9vtDKemwrLG6Tkuo83mwtJKrszrudUjEUgfum4n7zfIZblWKzz2N988TPvMzoWlRgDRaLlmk9cGi8GkvmqVR3KZcwkwktsyGmEFC99Hjh1/m3b55ZO/oLYtmzZQ29jwELXNzIQjHGslLlGVCvx1mZqao7Zqhcu21UEuo9Vq4Xlct4EnVJ2eC4+jE3m9dGcXIhHk7EIkgpxdiESQswuRCHJ2IRJBzi5EIvRVessVShgYCcsJPsOTF87OhCWvSo3LJ1ddzaWOG27cRm1jo+FoIgBoNcMS4IljR2if2YisVa/zyKtGpP7azAyvLccSRMYi5WJyjbHifADyeX6v6JBEm3mLJIc88u7sZ//Ed7/zN9S2+/Zd1Hbt1VcG27MKlw1bizx6bWiQS4D5An9u1uTSZ5vU4WtnvM/sfDiqsNNRrTchkkfOLkQiyNmFSAQ5uxCJIGcXIhH6uhufL5axflO4lNP28ibarzwVrvO0ecsVtM/uO2+itivG+Y5quRDOBwYAb70ZLg3VXuC7t1mbB/jESit1M3SHyeX4NbrdbgfbFxbCu7fd4/Gd6XKFz0cpEkwyPx8OAMpFduMXZrgscLwZzkMIAE+d+zW1nbgmvBs/P8dLgM0vcNun//Rz1HbnHVwVeOsILyvWaoeDnmbmwq8lAFRr64PtuYh6oju7EIkgZxciEeTsQiSCnF2IRJCzC5EIcnYhEmE55Z8eBvDHAE65+65e21cA/BmAyd6/fcndf7bkyQpFjIyHpZDbtvI8YrcWw/LPeERCq9UjclKZS0ae8etfpUbGGAuAyHhASzHjYzw/x4Ndch0uyZQsLNnlIwE57RY/XqXCn1sux5dPqRLO5eeRklFwLkW2YmWXFvhr9uvnXg+2NxcXaZ9KkQeTHCLyKwDcdief4+HRUWo7fOTVYHsGPh/rR8LSW6Rq2LLu7N8FcG+g/RvuflvvZ0lHF0KsLUs6u7s/BYDHHgohfie4nM/sXzCz/Wb2sJmtW7ERCSFWhUt19m8B2AHgNgDHAXyN/aOZ7TGzfWa2b5Z8hVIIsfpckrO7+0l377h7BuDbAGjxbHff6+4T7j4xWOMFGIQQq8slObuZXRy18ikAL67McIQQq8VypLfvA/gIgDEzOwrgywA+Yma3AXAAhwH8+XJOli8UsG4sLJfNNrj8U6yG5Z9KhUtoWUTGaTQj54pEvRVKYVsnEqEWk0JajVi0HC//VClHJLuF8EelzLgslMvx/HTn53m5o1KFP+98MfyaNVsRySuSFy4W6ecRW6EaLhHWzvhzbjXCuQYB4I2Dv6W2qXNn+DGbfCGcPXcq2L5QCkd7AnwNZBlf90s6u7t/NtD8naX6CSHeX+gbdEIkgpxdiESQswuRCHJ2IRJBzi5EIvQ14aRnGRZJ2ZpcpJTQ1NSJcB+uvOGaHTuobXGByz/1+gi1zc2FpbLNm8ORfADQHOXnuu46PsZz53g5rLfe4vLPmbOTwfaZWZ5wskiiCgGg1Y5Fy3F5sJOFZbmYFBkreVWJJL4cGOBlklqtsIxmJDqwey4uAb55hM/93//9/6W27duvp7ZiIbyQq5FxLDbCkmhMctadXYhEkLMLkQhydiESQc4uRCLI2YVIBDm7EInQV+mt2Wzi2NEjQdumzbxuWzkflkmGh7nksmEDT0bZbnE5qUQi2wBem+1P/vR+2ufsZDiiCQDGx8NJAwHAwMd48tRxajtzNlyn7Ff/5yl+vJO8jpqBS1TFiFza7IQlLyYzAYg8YyAX0eyyjPecmQkn7owlvizXeJLNajWS+HKeR6nNzXIbLLyuBgf5WhwcGgy25/ORyEE+AiHEBwk5uxCJIGcXIhHk7EIkgpxdiETo6258LmeolsPXl6Eazwm2fnA42L4jEuxSiJVkiuwwx3Yzx8fHg+3Dw7x0VWsrVxk8ErRQqfD5uGobD7xhxxxdx3f+/9f//CW1HT0eDkICgGab52rL58NLq1Lmz6sZyZ+WRfL8LUZKOc2T9OUDlSrtMzoWXm8AsPuua6jt6qu5rZAL58IDgEo1rCqNDPM+1VrYlo8oJLqzC5EIcnYhEkHOLkQiyNmFSAQ5uxCJIGcXIhGWU/5pK4C/BjCObrmnve7+TTMbBfBDANvQLQH1gLvzxGkAyqUidhDZaHCQS2XldeGK0MNDkUCSPA+SaedikhG//hkpoVQo8CCNYkQ+iUmArRbPxzZ/PhzcAQBm4fFP3Hkn7bMwx+fjfzz+t9Q2M8/LV7U74blqNrhMFiMW7BIrDTU2NhZsdxLUBABDQ7wA6fU3XEdtm67YSm0Gvg7y+fD8L8zyIKqZubCt1eKlzZZzZ28D+Et3vxHAXQD+wsxuBPAQgCfdfSeAJ3t/CyHepyzp7O5+3N2f7T2eBXAAwGYA9wF4pPdvjwD45CqNUQixArynz+xmtg3A7QCeBjDu7hcCq0+g+zZfCPE+ZdnObmZ1AI8C+KK7v+NDo7s7EP4AamZ7zGyfme2bngt/dVEIsfosy9nNrIiuo3/P3R/rNZ80s009+yYAwR0Dd9/r7hPuPjFc5xsfQojVZUlnNzNDtx77AXf/+kWmxwE82Hv8IICfrvzwhBArxXKi3n4fwOcAvGBmz/XavgTgqwB+ZGafB/AmgAeWOlAuD9RqYZmqUuTy1fBgOKos6/AIqnwukosrUvqn3eYljc6fD+cRm507R/vUqxHJxfgYy5Got2qFHzPzsPRSKfDr+m233kJtr7z6KrU984/7qa3tYaksi0hesfx0pRK3jY3xfIMNIvVNR8prtTtc9ixEPGZhkZfYOj/LJccN4yRqMsfl6BJZO0x6BZbh7O7+DwCYJ96zVH8hxPsDfYNOiESQswuRCHJ2IRJBzi5EIsjZhUiEviaczLIO5hfOBW2jg1tov0o5HMGWy/HyOO78OnbmzBlqm5oKl08CgHIlLHfMzfMotHI+Uk4qEvVWrfKEiMUSl+wajXAkWrPJJcXh4XApIQC4/kM8yuvw4beo7cx0eE7abR69VixGpNRINGKhwOej2eSSLiOWCLQZiUZsNrjNjL+e5XJ4jYwOj9A+8zPhb6NGJWdqEUJ8oJCzC5EIcnYhEkHOLkQiyNmFSAQ5uxCJ0FfpreN5zHTCET6TbR7VVM2HbWXwRIkklwYAYG6Gy2uvvfIitV27I1zLK5fxc83OTFPbukj9tWjiSxqXBCycD0dX5XI8EWGtzuWaO27ZRW2vHThIbVMvvBRsb3e4BFg2Ll15ZKlOnZukNkP4uY2N8bnfOL6R2kr5TdQ2VOf96gN8/Ia5YLsvcgkwn4XnMZbEVHd2IRJBzi5EIsjZhUgEObsQiSBnFyIR+rob32pnOHY6nKerPMR3ESuD4ay0xUJkt5JvMGPjhhFqOzvO85nlSAmiTiS4oxApTZRlXE1otfiutRlXLjqk7FK1FgkyAT9XvcbPtXFslNpaJPCmEwkyqQ/yc42P813wfCQg6szpc8H2HTu283NtGKa2apnvuA8OcFsud5baOp2wTywucHUix+7Trt14IZJHzi5EIsjZhUgEObsQiSBnFyIR5OxCJMKS0puZbQXw1+iWZHYAe939m2b2FQB/BuBCFMKX3P1nsWOVinlcvSks14wNc/lk6lQ411m7Hs63BgClCi+d01jgZXrGN3LprdkIS2XFMtf5SmUuJ42MjFBbu80DV+bmwoETAFCvh0tDlYpc8jJSMgqIlzu6YhMPJikQpa/Y4XN18823UtuuXbxEVc74ICcnw2Webrj+Q7RPKRI01M64rdXhUmp7kZd/YhJsvcDXcK1C8jLGcvVRyz/RBvCX7v6smQ0CeMbMnujZvuHu/3kZxxBCrDHLqfV2HMDx3uNZMzsAYPNqD0wIsbK8p8/sZrYNwO0Anu41fcHM9pvZw2a2bqUHJ4RYOZbt7GZWB/AogC+6+wyAbwHYAeA2dO/8XyP99pjZPjPbNzPLP2sKIVaXZTm7mRXRdfTvuftjAODuJ9294+4ZgG8D2B3q6+573X3C3SeGBnldcSHE6rKks5uZAfgOgAPu/vWL2i+OTPgUAJ7PSQix5ixnN/73AXwOwAtm9lyv7UsAPmtmt6Erxx0G8OdLHShnQDUfloCsyd/it+fD16Rz81x6Q4lLedNz4dI5ADB+xZXU1miGZZfBwXBePQCwHM8Xl5EoOiBeCqlc5pIMszWaPBeeGZfDYqWmhkfC8g8A5MnKKkTOFbv3XLuDl6HKRSILP/axcN7AfOR1WZjjc3XqBI9em5nl/TZEIukylsNwkct8TSLNeiTqbTm78f8ABDMcRjV1IcT7C32DTohEkLMLkQhydiESQc4uRCLI2YVIhL4mnCwW8tgyHv5WbavNo4I6i7PB9mqVX6sWmjzKq1jkskulwqPUBmphqYwLaMD4Bh5FN1gPJ9IE4nJSTF5hct55HuiHdhaJiONTheFh/iWpYjEssc03eHLLt4+dpLaYTDk4OEhtzWZYno3N7/wCl3SbbZ4EsrnIJ3lmlo8/64SPWYxE2M1Mh+eq2eKRd7qzC5EIcnYhEkHOLkQiyNmFSAQ5uxCJIGcXIhH6Kr2ZAQUS9BSL8pqZDkepWSUiXUUEsfpARDKKRHlVB8KRdLXhMdpneIQn8ImNMSav5SOF7FpEevGMX9fbTX68TidSOyyS3PDaa8NRas+/+AbtsxCpbbawwKXZoSEedXj48G+D7d00DGHakdp95cg6bUbq802d45KYebjfcERazhNHiiilurMLkQpydiESQc4uRCLI2YVIBDm7EIkgZxciEfoqvbk72p1wJE+lxCWNQSKt0ER9ANqR6KShdeF6c0D86lethRMs1iNRVzEtJOtwiafZ5DJOqcQj8zqdcARbsxlJfNnky6DViEiYNZ5E8dMP/Mtge6H0c9qn3eLRZrWIXDo7G46KBIAWWQfRJKHG12JsncIjkZaRBJfeCb+eA3UuiY5tCEu6xcja0J1diESQswuRCHJ2IRJBzi5EIsjZhUiEJXfjzawC4CkA5d7//9jdv2xm2wH8AMB6AM8A+Jw7+UZ/jyzLMDsfztPVzvguZ7EYDkCJ7cbnI0EajUiusFw5YiP56SwSmJJFAlosYmuT8j5APEhmcTEcMDI3y3e6LRLsUszz12VkuEpt9fxIsP3uuz9O++SML5/Y7vn+F56ltqu3bQm2X3VVuB0A5s/zoJXY2hlZx9WJaqQcWUZe63w2Q/tMTU8F25kaAyzvzt4A8FF3vxXd8sz3mtldAP4KwDfc/VoAUwA+v4xjCSHWiCWd3btcqLpY7P04gI8C+HGv/REAn1yNAQohVobl1mfP9yq4ngLwBICDAM65+4X3H0cBbF6VEQohVoRlObu7d9z9NgBbAOwGcP1yT2Bme8xsn5ntOzfDyzILIVaX97Qb7+7nAPwKwD8DMGJmFzb4tgA4RvrsdfcJd58YGeJfeRRCrC5LOruZbTCzkd7jKoCPAziArtP/Se/fHgTw01UaoxBiBVhOIMwmAI+YWR7di8OP3P1vzexlAD8ws/8I4B8BfGepA1nOUCmHpZxmJMcYq4LTcS55ja7j7yJiARfNOR5U0ZgLD6ReW0/7oMClK/OIvAYuoSxGSijNz4fnMYucyyKX/CzHl0ieSKIA0CIS4Kb1sdeFy1pnT71FbXMzZ6jNO1cSA39e9VqZ2qoVbovEuqDV4HKek9JWjXn+mjXa4TWcOX8xl3R2d98P4PZA+yF0P78LIX4H0DfohEgEObsQiSBnFyIR5OxCJIKcXYhEsFgE1YqfzGwSwJu9P8cAnO7byTkaxzvRON7J79o4rnb3DSFDX539HSc22+fuE2tyco1D40hwHHobL0QiyNmFSIS1dPa9a3jui9E43onG8U4+MONYs8/sQoj+orfxQiTCmji7md1rZq+a2Rtm9tBajKE3jsNm9oKZPWdm+/p43ofN7JSZvXhR26iZPWFmr/d+h+v7rP44vmJmx3pz8pyZfaIP49hqZr8ys5fN7CUz+ze99r7OSWQcfZ0TM6uY2a/N7PneOP5Dr327mT3d85sfmhmv9RTC3fv6AyCPblqrawCUADwP4MZ+j6M3lsMAxtbgvH8A4A4AL17U9p8APNR7/BCAv1qjcXwFwL/t83xsAnBH7/EggNcA3NjvOYmMo69zgm6FwHrvcRHA0wDuAvAjAJ/ptf8XAP/6vRx3Le7suwG84e6HvJt6+gcA7luDcawZ7v4UgLPvar4P3cSdQJ8SeJJx9B13P+7uz/Yez6KbHGUz+jwnkXH0Fe+y4kle18LZNwO4OBPBWiardAC/MLNnzGzPGo3hAuPufrz3+ASA8TUcyxfMbH/vbf6qf5y4GDPbhm7+hKexhnPyrnEAfZ6T1UjymvoG3Yfd/Q4AfwTgL8zsD9Z6QED3yo7uhWgt+BaAHejWCDgO4Gv9OrGZ1QE8CuCL7v6OCgn9nJPAOPo+J34ZSV4Za+HsxwBsvehvmqxytXH3Y73fpwD8BGubeeekmW0CgN7vU2sxCHc/2VtoGYBvo09zYt2i6I8C+J67P9Zr7vuchMaxVnPSO/c5vMckr4y1cPbfANjZ21ksAfgMgMf7PQgzq5nZ4IXHAP4QwIvxXqvK4+gm7gTWMIHnBefq8Sn0YU7MzNDNYXjA3b9+kamvc8LG0e85WbUkr/3aYXzXbuMn0N3pPAjg363RGK5BVwl4HsBL/RwHgO+j+3awhe5nr8+jWzPvSQCvA/glgNE1Gsd/A/ACgP3oOtumPozjw+i+Rd8P4Lnezyf6PSeRcfR1TgDcgm4S1/3oXlj+/UVr9tcA3gDw3wGU38tx9Q06IRIh9Q06IZJBzi5EIsjZhUgEObsQiSBnFyIR5OxCJIKcXYhEkLMLkQj/H0AbBgEuV4ucAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "j = 275\n",
    "x, mu, log_var, z = model.predict([x_data[j].reshape(1,32,32,3), y_data[j].reshape(1,10)])\n",
    "plt.imshow(x_data[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe596c079d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe596cd75b0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image, ImageEnhance\n",
    "z_ex = np.random.normal(0, 1, (1,100))\n",
    "y = y_data[10].reshape(1,10)\n",
    "z_ex.shape\n",
    "out = tf.keras.activations.sigmoid(model.decoder([z_ex, y]))\n",
    "im = tf.keras.preprocessing.image.array_to_img(out[0])\n",
    "enhancer = ImageEnhance.Sharpness(im)\n",
    "\n",
    "factor = 5\n",
    "im_s_1 = enhancer.enhance(factor)\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(im_s_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
