{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Input, Flatten,\\\n",
    "Conv2DTranspose, BatchNormalization, LeakyReLU, Reshape, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import plotly\n",
    "# import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "img_chn = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset-\n",
    "(train_images, y_train), (test_images, y_test) = cifar10.load_data()\n",
    "if img_chn == 1:\n",
    "    train_images = train_images.mean(axis=3)                                                                                    \n",
    "    test_images = test_images.mean(axis=3)                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (img_rows, img_cols, img_chn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensions of training and testing sets are:\n",
      "X_train.shape: (50000, 32, 32, 1) & X_test.shape: (10000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Specify hyper-parameters-\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "num_epochs = 100\n",
    "\n",
    "# Convert datasets to floating point types-\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "\n",
    "# Normalize the training and testing datasets-\n",
    "if img_chn == 1:\n",
    "    train_images = train_images.reshape((train_images.shape[0], \\\n",
    "                                         img_rows, img_rows, img_chn)) / 255.\n",
    "    test_images = test_images.reshape((test_images.shape[0], \\\n",
    "                                      img_rows, img_rows, img_chn)) / 255.\n",
    "else:\n",
    "    train_images = train_images/255.\n",
    "    test_images = test_images/255.\n",
    "\n",
    "\n",
    "print(\"\\nDimensions of training and testing sets are:\")\n",
    "print(f\"X_train.shape: {train_images.shape} & X_test.shape: {test_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1563,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batch_creation(X_data, batch_size):\n",
    "    end = X_data.shape[0]-1\n",
    "    start = 0\n",
    "    batch_split_X = list()\n",
    "    while start < end:\n",
    "        img_slice = np.array(X_data[start:start+batch_size])\n",
    "        batch_split_X.append(img_slice)\n",
    "        start = start + batch_size\n",
    "    return np.array(batch_split_X, dtype=object)\n",
    "    \n",
    "train_dataset = batch_creation(train_images, 32)\n",
    "test_dataset = batch_creation(test_images, 32)\n",
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_outlier_detector = True\n",
    "\n",
    "latent_dim = 1024\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "# train_size = train_images.shape[0]\n",
    "# batch_size = 32\n",
    "# test_size = test_images.shape[0]\n",
    "\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "# train_dataset = train_dataset.shuffle(train_size)\n",
    "# train_dataset = train_dataset.batch(batch_size)\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices(test_images)\\\n",
    "#             .shuffle(test_size).batch(batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "    \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "              [\n",
    "                  tf.keras.layers.InputLayer(input_shape),\n",
    "                  tf.keras.layers.Conv2D(32, 3, strides=2, padding='same', activation=tf.nn.relu),\n",
    "                  tf.keras.layers.Conv2D(64, 3, strides=2,  padding='same', activation=tf.nn.relu),\n",
    "                  tf.keras.layers.Conv2D(128, 3, strides=2,  padding='same', activation=tf.nn.relu),\n",
    "                  tf.keras.layers.Flatten(),\n",
    "                  # No activation\n",
    "                  tf.keras.layers.Dense(latent_dim + latent_dim ),\n",
    "              ]\n",
    "        )\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=4*4*128, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(4, 4, 128)),\n",
    "            tf.keras.layers.Conv2DTranspose(64, 3, strides=2, padding='same',  activation=tf.nn.relu),\n",
    "            tf.keras.layers.Conv2DTranspose(32, 3, strides=2, padding='same',  activation=tf.nn.relu),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2DTranspose(img_chn, 3, strides=2, padding='same'),\n",
    "#             No activation\n",
    "#             tf.keras.layers.Conv2DTranspose(\n",
    "#                 filters=1, kernel_size=3, strides=1, padding='same'),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    @tf.function\n",
    "    def sample(self, z=None):\n",
    "        if z is None:\n",
    "            z = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        return self.decode(z, apply_sigmoid=True)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "    \n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits\n",
    "    @tf.function\n",
    "    def train_step(self, x, optimizer):\n",
    "        \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "        This function computes the loss and gradients, and uses the latter to\n",
    "        update the model's parameters.\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = compute_loss(model, x)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "        axis=raxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 16, 16, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              4196352   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,289,024\n",
      "Trainable params: 4,289,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 2048)              2099200   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 8, 8, 64)         73792     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 1)        289       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,191,745\n",
      "Trainable params: 2,191,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CVAE(latent_dim)\n",
    "model.encoder.summary()\n",
    "model.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_images(model, n, epoch, im_size=32, save=True, first_epoch=False, f_ep_count=0):\n",
    "    pass\n",
    "    \n",
    "#     # Create image matrix \n",
    "#     image_width = im_size*n\n",
    "#     image_height = image_width\n",
    "#     image = np.zeros((image_height, image_width, img_chn))\n",
    "\n",
    "#     # Create list of values which are evenly spaced wrt probability mass\n",
    "\n",
    "#     norm = tfp.distributions.Normal(0, 1)\n",
    "#     grid_x = norm.quantile(np.linspace(0.05, 0.95, n))\n",
    "#     grid_y = norm.quantile(np.linspace(0.05, 0.95, n))\n",
    "    \n",
    "#     # For each point on the grid in the latent space, decode and\n",
    "\n",
    "# #     # copy the image into the image array\n",
    "# #     for i, yi in enumerate(grid_x):\n",
    "# #         for j, xi in enumerate(grid_y):\n",
    "# #             z = np.array([[xi, yi]])\n",
    "# #             x_decoded = model.sample(z)\n",
    "# #             digit = tf.reshape(x_decoded[0], (im_size, im_size, img_chn))\n",
    "# #             image[i * im_size: (i + 1) * im_size,\n",
    "# #                   j * im_size: (j + 1) * im_size] = digit.numpy()\n",
    "    \n",
    "\n",
    "#     # Plot the image array\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.imshow(image, cmap='Greys_r')\n",
    "#     plt.axis('Off')\n",
    "\n",
    "\n",
    "#     # Potentially save, with different formatting if within first epoch\n",
    "#     if save and first_epoch:\n",
    "#         plt.savefig('tf_grid_at_epoch_{:04d}.{:04d}.png'.format(epoch, f_ep_count))\n",
    "#     elif save:\n",
    "#         plt.savefig('tf_grid_at_epoch_{:04d}.png'.format(epoch))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Test set ELBO: 663.8363647460938, time elapse for current epoch: 11.243090391159058\n",
      "Epoch: 2, Test set ELBO: 655.3274536132812, time elapse for current epoch: 7.195418834686279\n",
      "Epoch: 3, Test set ELBO: 653.3447265625, time elapse for current epoch: 6.787143230438232\n",
      "Epoch: 4, Test set ELBO: 652.3555908203125, time elapse for current epoch: 6.766752004623413\n",
      "Epoch: 5, Test set ELBO: 652.126220703125, time elapse for current epoch: 7.201196908950806\n",
      "Epoch: 6, Test set ELBO: 651.52392578125, time elapse for current epoch: 7.829582691192627\n",
      "Epoch: 7, Test set ELBO: 650.8648681640625, time elapse for current epoch: 7.216124057769775\n",
      "Epoch: 8, Test set ELBO: 650.1179809570312, time elapse for current epoch: 7.117692708969116\n",
      "Epoch: 9, Test set ELBO: 649.0217895507812, time elapse for current epoch: 7.341246843338013\n",
      "Epoch: 10, Test set ELBO: 647.7882690429688, time elapse for current epoch: 7.240871906280518\n",
      "Epoch: 11, Test set ELBO: 646.582275390625, time elapse for current epoch: 6.978524684906006\n",
      "Epoch: 12, Test set ELBO: 645.9218139648438, time elapse for current epoch: 7.0841381549835205\n",
      "Epoch: 13, Test set ELBO: 644.7216796875, time elapse for current epoch: 7.414200782775879\n",
      "Epoch: 14, Test set ELBO: 643.41357421875, time elapse for current epoch: 6.858818054199219\n",
      "Epoch: 15, Test set ELBO: 642.5511474609375, time elapse for current epoch: 7.315098524093628\n",
      "Epoch: 16, Test set ELBO: 641.7582397460938, time elapse for current epoch: 7.0419042110443115\n",
      "Epoch: 17, Test set ELBO: 641.2410888671875, time elapse for current epoch: 7.202656030654907\n",
      "Epoch: 18, Test set ELBO: 640.49658203125, time elapse for current epoch: 6.930841445922852\n",
      "Epoch: 19, Test set ELBO: 640.0469360351562, time elapse for current epoch: 7.037343740463257\n",
      "Epoch: 20, Test set ELBO: 639.6256713867188, time elapse for current epoch: 6.492441415786743\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tf.config.run_functions_eagerly(False)\n",
    "plot_latent_images(model, 10, epoch=0)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    for idx, train_x in enumerate(train_dataset):\n",
    "        model.train_step(train_x, optimizer)\n",
    "        if epoch == 1 and idx % 75 == 0:\n",
    "            plot_latent_images(model, 10, epoch=epoch, first_epoch=True, f_ep_count=idx)          \n",
    "    end_time = time.time()\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for test_x in test_dataset:\n",
    "        loss(compute_loss(model, test_x))\n",
    "    elbo = loss.result()\n",
    "    #display.clear_output(wait=False)\n",
    "    print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "        .format(epoch, elbo, end_time - start_time))\n",
    "    if epoch != 1:\n",
    "        plot_latent_images(model, 20, epoch=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, var = model.encode(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = model.reparameterize(mean, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = model.decode(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fccf67290d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "i=50\n",
    "plt.imshow(test_images[i],cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fccf66953a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(recon[i],  cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "znp = z.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_embedded \u001b[38;5;241m=\u001b[39m \u001b[43mTSNE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mznp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/manifold/_t_sne.py:1117\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \n\u001b[1;32m   1100\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;124;03m        Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1117\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/manifold/_t_sne.py:1013\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;66;03m# Degrees of freedom of the Student's t-distribution. The suggestion\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;66;03m# degrees_of_freedom = n_components - 1 comes from\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# \"Learning a Parametric Embedding by Preserving Local Structure\"\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# Laurens van der Maaten, 2009.\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m degrees_of_freedom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tsne\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegrees_of_freedom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_embedded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_embedded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneighbors_nn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_num_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_num_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/manifold/_t_sne.py:1081\u001b[0m, in \u001b[0;36mTSNE._tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     opt_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmomentum\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n\u001b[1;32m   1080\u001b[0m     opt_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_iter_without_progress\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_without_progress\n\u001b[0;32m-> 1081\u001b[0m     params, kl_divergence, it \u001b[38;5;241m=\u001b[39m \u001b[43m_gradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopt_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;66;03m# Save the final number of iterations\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m it\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/manifold/_t_sne.py:398\u001b[0m, in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m# only compute the error when needed\u001b[39;00m\n\u001b[1;32m    396\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m check_convergence \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m==\u001b[39m n_iter \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 398\u001b[0m error, grad \u001b[38;5;241m=\u001b[39m \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m linalg\u001b[38;5;241m.\u001b[39mnorm(grad)\n\u001b[1;32m    401\u001b[0m inc \u001b[38;5;241m=\u001b[39m update \u001b[38;5;241m*\u001b[39m grad \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/manifold/_t_sne.py:279\u001b[0m, in \u001b[0;36m_kl_divergence_bh\u001b[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001b[0m\n\u001b[1;32m    276\u001b[0m indptr \u001b[38;5;241m=\u001b[39m P\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    278\u001b[0m grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(X_embedded\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m--> 279\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[43m_barnes_hut_tsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_P\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_embedded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdegrees_of_freedom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m (degrees_of_freedom \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m/\u001b[39m degrees_of_freedom\n\u001b[1;32m    293\u001b[0m grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mravel()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_embedded = TSNE(n_components=2, learning_rate='auto',init='random').fit_transform(znp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.confusion_matrix(y_test, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
